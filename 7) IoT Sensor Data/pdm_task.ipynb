{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Things\n",
    "\n",
    "## Lecture : IoT and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h5> 7) IoT and sensor data </h5>\n",
    "<ul>\n",
    "    <li> There are two hand-in exercises for this topic:</li>\n",
    "       <ul>\n",
    "        <li>i. The first one is explained in bullet 2 of slide 16 of the slide deck “IoT & Sensor\n",
    "        </li>Data.pptx”. You need to do the entire task described in bullet 2 of slide 16.\n",
    "        <li>ii. The second one is related to PCA and it is explained in the notebook “pdm_task”.\n",
    "            Note that the data simulation parts are already done for you, so you do not need\n",
    "            to do those parts. You should start from the cell where tasks are listed and you\n",
    "        </li> need to do all 5 tasks.\n",
    "        </ul>\n",
    "</ul>\n",
    "\n",
    "<h5> bullet 2 of slide 16</h5>\n",
    "<ul><li>Now, try youself:<br> Use the diabetes.csv dataset to do the following:</li>\n",
    " <ol>\n",
    "    <li>Select the following 4 attributes(3 features+1 class label):</li>\n",
    "        <ul><li>Glucose, BloodPreasure, Insulin, Outcome</li></ul>\n",
    "    <li>Normalize Glucose, BloodPressure and Insulin to [0,1] using MinMax.</li>\n",
    "    <li>Store the new data(3 normalized features + 1 class label) in another dataset S.</li>\n",
    "    <li>Modify the MQTT example to do the following:</li>\n",
    "        <ul>\n",
    "            <li>The publisher publishes records in 5 continuously, When it reaches the end of S, it continues to send from the beginning again.</li>\n",
    "            <li>The subscriber continuously receices the data. For each latest record r received, apply the 3NN classification to the last 5 records before r, and compare the classification result with the Outcome label in r.</li>\n",
    "            <ul><li>Repeat this for 1000 times. and report the number of correct classifications.</li></ul>\n",
    "        </ul>\n",
    " </ol>\n",
    "</ul>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate sensor data & apply PCA\n",
    "\n",
    "In this exercise, you will do the following:\n",
    "1. Simulate sensor data\n",
    "2. Apply PCA to simulated data\n",
    "3. Simulate a new point\n",
    "4. Find out which region the new point belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data:\n",
      "     Sensor1    Sensor2    Sensor3    Sensor4    Sensor5    Sensor6  \\\n",
      "0  59.934283  36.430105  56.965725  10.388561  40.562849  51.964123   \n",
      "1  47.239714  43.895011  55.671472  28.905288  70.259050  48.722836   \n",
      "2  62.963772  38.062380  31.279604  38.269433  46.046264  69.045816   \n",
      "3  80.475599  52.223362  61.606686  53.008380  51.826387  80.671624   \n",
      "4  45.336935  73.963573  20.218348  70.503249  64.367814  63.756941   \n",
      "\n",
      "     Sensor7    Sensor8    Sensor9   Sensor10   Sensor11   Sensor12  \\\n",
      "0  51.576755  56.403048  63.280022  69.217891  70.611892  66.017477   \n",
      "1  61.262950  72.314233  44.082680  42.605706  26.897905  49.021813   \n",
      "2  56.832040  19.905237  48.678273  38.418383  61.518745  41.079748   \n",
      "3  24.456718  84.807115  46.507354  68.681245  37.630232  53.375301   \n",
      "4  46.295596  56.621738  60.301076  -4.610793  43.471946   7.484493   \n",
      "\n",
      "    Sensor13   Sensor14   Sensor15   Sensor16   Sensor17   Sensor18  \\\n",
      "0  45.626995  72.350652  44.689254  77.397560  78.652455  13.535035   \n",
      "1  57.663772  55.924865  32.846243  47.839698  30.996639  43.242011   \n",
      "2  64.712840  57.699750  58.957432  28.348263  80.791904  50.558823   \n",
      "3  26.347709  25.898816  29.722450  77.854218  67.340775  65.921706   \n",
      "4  52.034782  58.049158  72.706695  47.756466  31.983535  50.238633   \n",
      "\n",
      "    Sensor19   Sensor20  \n",
      "0  58.255621  69.225168  \n",
      "1  85.468972  78.684232  \n",
      "2  19.530576  49.933817  \n",
      "3  46.339473  54.707042  \n",
      "4  47.968296  35.593104  \n"
     ]
    }
   ],
   "source": [
    "# Step 1 Simulate synthetic predictive maintenance dataset\n",
    "np.random.seed(42)\n",
    "time_steps = 10000\n",
    "\n",
    "sensors = {}\n",
    "for i in range(1, 21):\n",
    "    sensors[f'Sensor{i}'] = np.linspace(50, 100, time_steps) + np.random.normal(0, 20, time_steps)\n",
    "\n",
    "# Combine into a DataFrame\n",
    "data = pd.DataFrame(sensors)\n",
    "\n",
    "print(\"Sample Data:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Data Sample:\n",
      "    Sensor1   Sensor2   Sensor3   Sensor4   Sensor5   Sensor6   Sensor7  \\\n",
      "0 -0.610580 -1.566006 -0.725010 -2.596654 -1.407431 -0.927666 -0.969437   \n",
      "1 -1.126525 -1.265030 -0.777771 -1.850742 -0.198347 -1.057996 -0.572396   \n",
      "2 -0.487452 -1.500195 -1.772111 -1.473524 -1.184173 -0.240819 -0.754021   \n",
      "3  0.224281 -0.929241 -0.535820 -0.879792 -0.948835  0.226649 -2.081098   \n",
      "4 -1.203859 -0.052701 -2.223025 -0.175043 -0.438209 -0.453482 -1.185914   \n",
      "\n",
      "    Sensor8   Sensor9  Sensor10  Sensor11  Sensor12  Sensor13  Sensor14  \\\n",
      "0 -0.746813 -0.479506 -0.232249 -0.186682 -0.367113 -1.184181 -0.110562   \n",
      "1 -0.106939 -1.258090 -1.320570 -1.955170 -1.054209 -0.697301 -0.772550   \n",
      "2 -2.214587 -1.071707 -1.491814 -0.554553 -1.375289 -0.412171 -0.701019   \n",
      "3  0.395468 -1.159753 -0.254195 -1.520984 -0.878208 -1.964016 -1.982653   \n",
      "4 -0.738018 -0.600323 -3.251518 -1.284652 -2.733470 -0.924990 -0.686938   \n",
      "\n",
      "   Sensor15  Sensor16  Sensor17  Sensor18  Sensor19  Sensor20  \n",
      "0 -1.220616  0.099576  0.149868 -2.489953 -0.664518 -0.238621  \n",
      "1 -1.696973 -1.108663 -1.769317 -1.291246  0.441852  0.145353  \n",
      "2 -0.646714 -1.905416  0.236027 -0.996005 -2.238900 -1.021719  \n",
      "3 -1.822619  0.118243 -0.305674 -0.376097 -1.148973 -0.827958  \n",
      "4 -0.093683 -1.112065 -1.729573 -1.008925 -1.082753 -1.603855  \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Display scaled data\n",
    "print(\"Scaled Data Sample:\")\n",
    "print(pd.DataFrame(scaled_data, columns=data.columns).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the following tasks:\n",
    "1. Apply PCA with upto 5 components\n",
    "2. Visualize how much variance of the dataset is defined by each component\n",
    "3. Visualize the first 2 principal components and color them by timestep\n",
    "4. Simulate a new position using code below\n",
    "5. Plot the new point in the original 2D PCA graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Simulate a new observation and predict its position\n",
    "new_observation = np.array([[75] * 20])\n",
    "scaled_new_observation = scaler.transform(new_observation)\n",
    "new_pca = pca.transform(scaled_new_observation)\n",
    "\n",
    "print(\"New observation PCA position:\", new_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task from slides</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 1 Select the following 4 attributes (3 features+1 class label): Glucose, BLoodPreasure, Insulin, Outcome</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df[['Glucose', 'BloodPressure', 'Insulin', 'Outcome']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 2 Normalize Glucose, BloodPressure and Insulin to [0,1] using MinMax <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df_selected[['Glucose', 'BloodPressure', 'Insulin']] = scaler.fit_transform(df_selected[['Glucose', 'BloodPressure', 'Insulin']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 3 Store the new data(3 normalized features + 1 class label) in another dataset S.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = df_selected.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 4  </h3>\n",
    "    <li>Modify the MQTT example to do the following:</li>\n",
    "        <ul>\n",
    "            <li>The publisher publishes records in 5 continuously, When it reaches the end of S, it continues to send from the beginning again.</li>\n",
    "            <li>The subscriber continuously receices the data. For each latest record r received, apply the 3NN classification to the last 5 records before r, and compare the classification result with the Outcome label in r.</li>\n",
    "            <ul><li>Repeat this for 10000 times. and report the number of correct classifications.</li></ul>\n",
    "        </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Simulate MQTT publish/subscribe loop</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000, Correct Predictions: 613, Accuracy so far: 0.62\n",
      "Correct classifications: 613, Total iterations: 1000, Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000 #Total times to simulate receiving new record\n",
    "window_size = 5  #How many past records to keep as a training set\n",
    "k_neighbors = 3 #Neighbor count in KNN / 3-NN for classification\n",
    "correct_predictions = 0 \n",
    "\n",
    "records = S.values.tolist()\n",
    "n_records = len(records)\n",
    "\n",
    "#Each loop simulates a message received from the stream.\n",
    "for i in range(iterations):\n",
    "    index = i % n_records  # Simulate receiving records in a circular manner. Wraps around to row 1\n",
    "    r = records[index] \n",
    "\n",
    "\n",
    "    if i >= window_size: # Only start predicting once we have window_size records before r\n",
    "\n",
    "        start_index = (index - window_size) % n_records  # Around around\n",
    "\n",
    "\n",
    "        if start_index + window_size <= n_records: #Get the last window_size records before r\n",
    "            train_data = records[start_index:start_index + window_size]\n",
    "        else:\n",
    "            # If the window wraps around, split into two slices\n",
    "            train_data = records[start_index:] + records[:(start_index + window_size) % n_records]\n",
    "        #Spliting the features (X) and labels (y)\n",
    "        train_X = [row[:3] for row in train_data] # First 3 columns = features\n",
    "        train_y = [row[3] for row in train_data] # Last column = label / target\n",
    "\n",
    "        # Fit the KNN classifier\n",
    "        knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
    "        knn.fit(train_X, train_y)\n",
    "\n",
    "        # Predict the class for the current record r\n",
    "        pred = knn.predict([r[:3]])[0]\n",
    "\n",
    "        if pred == r[3]:\n",
    "            correct_predictions += 1 # we count the correct predictions\n",
    "\n",
    "        if (i+1) % 1000 == 0:\n",
    "            made_predictions = max(0, (i + 1) - window_size)\n",
    "            if made_predictions > 0:\n",
    "                print(f\"Iteration {i+1}, Correct Predictions: {correct_predictions}, Accuracy so far: {correct_predictions / made_predictions:.2f}\")\n",
    "\n",
    "\n",
    "denom = max(0, iterations - window_size)\n",
    "accuracy = (correct_predictions / denom) if denom > 0 else float('nan')\n",
    "\n",
    "print(f\"Correct classifications: {correct_predictions}, Total iterations: {iterations}, Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct predictions are 613/1000 means 62% prediction accuracy. But some of the predictions could be warm up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Outcome'])\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(X)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'explained_variance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mexplained_variance\u001b[49m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mcumsum(explained_variance), marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative Explained Variance by PCA Components\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Components\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'explained_variance' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance)+1), np.cumsum(explained_variance), marker='o')\n",
    "plt.title('Cumulative Explained Variance by PCA Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h5> 7) IoT and sensor data </h5>\n",
    "<ul>\n",
    "    <li> There are two hand-in exercises for this topic:</li>\n",
    "       <ul>\n",
    "        <li>i. The first one is explained in bullet 2 of slide 16 of the slide deck “IoT & Sensor\n",
    "        </li>Data.pptx”. You need to do the entire task described in bullet 2 of slide 16.\n",
    "        <li>ii. The second one is related to PCA and it is explained in the notebook “pdm_task”.\n",
    "            Note that the data simulation parts are already done for you, so you do not need\n",
    "            to do those parts. You should start from the cell where tasks are listed and you\n",
    "        </li> need to do all 5 tasks.\n",
    "        </ul>\n",
    "</ul>\n",
    "\n",
    "<h5> bullet 2 of slide 16</h5>\n",
    "<ul><li>Now, try youself:<br> Use the diabetes.csv dataset to do the following:</li>\n",
    " <ol>\n",
    "    <li>Select the following 4 attributes(3 features+1 class label):</li>\n",
    "        <ul><li>Glucose, BloodPreasure, Insulin, Outcome</li></ul>\n",
    "    <li>Normalize Glucose, BloodPressure and Insulin to [0,1] using MinMax.</li>\n",
    "    <li>Store the new data(3 normalized features + 1 class label) in another dataset S.</li>\n",
    "    <li>Modify the MQTT example to do the following:</li>\n",
    "        <ul>\n",
    "            <li>The publisher publishes records in 5 continuously, When it reaches the end of S, it continues to send from the beginning again.</li>\n",
    "            <li>The subscriber continuously receices the data. For each latest record r received, apply the 3NN classification to the last 5 records before r, and compare the classification result with the Outcome label in r.</li>\n",
    "            <ul><li>Repeat this for 10000 times. and report the number of correct classifications.</li></ul>\n",
    "        </ul>\n",
    " </ol>\n",
    "</ul>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
