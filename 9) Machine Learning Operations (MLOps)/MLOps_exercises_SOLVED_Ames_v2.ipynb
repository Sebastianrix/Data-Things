{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d52b51",
   "metadata": {},
   "source": [
    "# MLOps exercises — Solutions for Tasks 1–6 (Ames + Drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e0724",
   "metadata": {},
   "source": [
    "\n",
    "**Workflow overview**  \n",
    "- Use `AmesHousing.csv` for training.  \n",
    "- Mirror Step 5 from `MLOps.ipynb`: one-hot dummies for **Bldg Type** → `BType_*` and **Neighborhood** → `Nbh_*` with `drop_first=True`, `dtype=int`.  \n",
    "- Save/Load a **best model** + **feature levels**.  \n",
    "- Evaluate new datasets (MAE) and run simple drift checks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02cb8c",
   "metadata": {},
   "source": [
    "## Task 0 — Load training data & define feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62228115",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "TRAIN_CSV = '/mnt/data/AmesHousing.csv'\n",
    "\n",
    "ames_raw = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "num_features = [\"Lot Area\", \"Overall Cond\", \"Year Built\", \"Gr Liv Area\", \"Mo Sold\", \"Yr Sold\"]\n",
    "cat_features = [\"Bldg Type\", \"Neighborhood\"]\n",
    "target_col = \"SalePrice\"\n",
    "\n",
    "cols_needed = num_features + cat_features + [target_col]\n",
    "ames = ames_raw[cols_needed].copy()\n",
    "ames.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a10d20",
   "metadata": {},
   "source": [
    "## Task 1 — Preprocess new Ames data like Step 5 (`get_dummies` + drop originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f21eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_like_step5(df: pd.DataFrame, levels: list | None = None):\n",
    "    df = df.copy()\n",
    "    out = df.join(pd.get_dummies(df[\"Bldg Type\"], drop_first=True, dtype=\"int\", prefix=\"BType\"))\n",
    "    out = out.join(pd.get_dummies(out[\"Neighborhood\"], drop_first=True, dtype=\"int\", prefix=\"Nbh\"))\n",
    "    out = out.drop(columns=[\"Bldg Type\", \"Neighborhood\"])\n",
    "    # Separate features (drop target if present)\n",
    "    X = out.drop(columns=[c for c in [\"SalePrice\"] if c in out.columns])\n",
    "    # Align to training feature set\n",
    "    if levels is None:\n",
    "        levels = list(X.columns)\n",
    "    else:\n",
    "        for col in levels:\n",
    "            if col not in X.columns:\n",
    "                X[col] = 0\n",
    "        X = X[levels]\n",
    "    return X, levels\n",
    "\n",
    "# Fit levels on training data for later alignment\n",
    "X_levels_fit, feature_levels = preprocess_like_step5(ames.drop(columns=[target_col]))\n",
    "len(feature_levels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3244e",
   "metadata": {},
   "source": [
    "## Model artifacts — Load from `MLOps.ipynb` if present, else train & save a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f746912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "ART_DIR = r\"/mnt/data/ames_model_artifacts\"\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(ART_DIR, \"best_model.joblib\")\n",
    "levels_path = os.path.join(ART_DIR, \"feature_levels.json\")\n",
    "\n",
    "def train_and_save_baseline(ames_df):\n",
    "    X_all, levels_all = preprocess_like_step5(ames_df.drop(columns=['SalePrice']))  # uses current feature_levels form\n",
    "    y_all = ames_df['SalePrice'].values\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_all, y_all, test_size=0.2, random_state=1742)\n",
    "    rf = RandomForestRegressor(n_estimators=300, random_state=1742, n_jobs=-1)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    joblib.dump(rf, model_path)\n",
    "    with open(levels_path, \"w\") as f:\n",
    "        json.dump(list(X_all.columns), f)\n",
    "    return rf, list(X_all.columns)\n",
    "\n",
    "# Try load\n",
    "model = None\n",
    "levels_saved = None\n",
    "if os.path.exists(model_path) and os.path.exists(levels_path):\n",
    "    model = joblib.load(model_path)\n",
    "    with open(levels_path) as f:\n",
    "        levels_saved = json.load(f)\n",
    "else:\n",
    "    model, levels_saved = train_and_save_baseline(ames)\n",
    "\n",
    "type(model).__name__, len(levels_saved), model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c36040",
   "metadata": {},
   "source": [
    "## Task 2 — Function to evaluate a model on NEW Ames data (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e852085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def evaluate_new_data(csv_path: str, model, levels: list):\n",
    "    df_new = pd.read_csv(csv_path)\n",
    "    assert \"SalePrice\" in df_new.columns, \"New data must include SalePrice to compute MAE.\"\n",
    "    X_new, _ = preprocess_like_step5(df_new, levels=levels)\n",
    "    y_true = df_new[\"SalePrice\"].values\n",
    "    y_pred = model.predict(X_new)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return mae, pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred})\n",
    "\n",
    "\"Function ready ✅\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1b6c0",
   "metadata": {},
   "source": [
    "## Task 3 — Test on `NewAmesData1.csv` with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b842918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae1, preds1 = evaluate_new_data(\"/mnt/data/NewAmesData1.csv\", model, levels_saved)\n",
    "print(\"MAE on NewAmesData1.csv:\", round(mae1, 2))\n",
    "preds1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb8ea3",
   "metadata": {},
   "source": [
    "## Task 4 — Test on `NewAmesData2.csv` and note any drift signs later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7139ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mae2, preds2 = evaluate_new_data(\"/mnt/data/NewAmesData2.csv\", model, levels_saved)\n",
    "print(\"MAE on NewAmesData2.csv:\", round(mae2, 2))\n",
    "preds2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e032b",
   "metadata": {},
   "source": [
    "## Tasks 5–6 — Data drift checks (numeric: KS; categorical: Chi-squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "\n",
    "def drift_report(train_df: pd.DataFrame, new_df: pd.DataFrame, num_feats: list, cat_feats: list):\n",
    "    rows = []\n",
    "    # Numeric KS\n",
    "    for col in num_feats:\n",
    "        a = train_df[col].dropna()\n",
    "        b = new_df[col].dropna()\n",
    "        if len(a) > 0 and len(b) > 0:\n",
    "            stat, p = ks_2samp(a, b)\n",
    "            rows.append({\"feature\": col, \"type\": \"numeric\", \"test\": \"KS\", \"stat\": stat, \"p_value\": p, \"drift\": p < 0.05})\n",
    "    # Categorical Chi2\n",
    "    for col in cat_feats:\n",
    "        ct_train = pd.crosstab(train_df[col], \"train\").rename(columns={\"train\":\"train\"})\n",
    "        ct_new = pd.crosstab(new_df[col], \"new\").rename(columns={\"new\":\"new\"})\n",
    "        both = ct_train.join(ct_new, how=\"outer\").fillna(0)\n",
    "        try:\n",
    "            chi2, p, dof, exp = chi2_contingency(both.values)\n",
    "            rows.append({\"feature\": col, \"type\": \"categorical\", \"test\": \"Chi2\", \"stat\": chi2, \"p_value\": p, \"drift\": p < 0.05})\n",
    "        except Exception as e:\n",
    "            rows.append({\"feature\": col, \"type\": \"categorical\", \"test\": \"Chi2\", \"stat\": np.nan, \"p_value\": np.nan, \"drift\": False})\n",
    "    rep = pd.DataFrame(rows).sort_values([\"drift\",\"p_value\"], ascending=[False, True])\n",
    "    return rep\n",
    "\n",
    "train_slice = ames[num_features + cat_features + [target_col]].copy()\n",
    "new2 = pd.read_csv(\"/mnt/data/NewAmesData2.csv\")\n",
    "new4 = pd.read_csv(\"/mnt/data/NewAmesData4.csv\")\n",
    "\n",
    "report2 = drift_report(train_slice, new2, num_features, cat_features)\n",
    "report4 = drift_report(train_slice, new4, num_features, cat_features)\n",
    "\n",
    "report2.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec971c6",
   "metadata": {},
   "source": [
    "### Task 5 — Which variables drift in `NewAmesData2.csv`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report2.sort_values([\"drift\",\"p_value\"], ascending=[False, True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0937e404",
   "metadata": {},
   "source": [
    "### Task 6 — Which variables drift in `NewAmesData4.csv`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report4.sort_values([\"drift\",\"p_value\"], ascending=[False, True])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
